{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QULdbScxicdI",
        "outputId": "686dd862-bdc5-4473-c22b-024fefbd9916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\n",
            "================================================================================\n",
            "\n",
            "1. DATASET OVERVIEW\n",
            "--------------------------------------------------------------------------------\n",
            "Dataset Shape: (4024, 16)\n",
            "\n",
            "Columns: ['Age', 'Race ', 'Marital Status', 'Unnamed: 3', 'T Stage ', 'N Stage', '6th Stage', 'Grade', 'A Stage', 'Tumor Size', 'Estrogen Status', 'Progesterone Status', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Status']\n",
            "\n",
            "First 5 rows:\n",
            "   Age                                              Race   \\\n",
            "0   43  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "1   47  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "2   67                                              White   \n",
            "3   46                                              White   \n",
            "4   63                                              White   \n",
            "\n",
            "                   Marital Status  Unnamed: 3 T Stage  N Stage 6th Stage  \\\n",
            "0  Married (including common law)         NaN       T2      N3      IIIC   \n",
            "1  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "2  Married (including common law)         NaN       T2      N1       IIB   \n",
            "3                        Divorced         NaN       T1      N1       IIA   \n",
            "4  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "\n",
            "                                 Grade   A Stage  Tumor Size Estrogen Status  \\\n",
            "0  Moderately differentiated; Grade II  Regional          40        Positive   \n",
            "1  Moderately differentiated; Grade II  Regional          45        Positive   \n",
            "2     Poorly differentiated; Grade III  Regional          25        Positive   \n",
            "3  Moderately differentiated; Grade II  Regional          19        Positive   \n",
            "4  Moderately differentiated; Grade II  Regional          35        Positive   \n",
            "\n",
            "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
            "0            Positive                      19                     11   \n",
            "1            Positive                      25                      9   \n",
            "2            Positive                       4                      1   \n",
            "3            Positive                      26                      1   \n",
            "4            Positive                      21                      5   \n",
            "\n",
            "   Survival Months Status  \n",
            "0                1  Alive  \n",
            "1                2  Alive  \n",
            "2                2   Dead  \n",
            "3                2   Dead  \n",
            "4                3   Dead  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4024 entries, 0 to 4023\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Age                     4024 non-null   int64  \n",
            " 1   Race                    4024 non-null   object \n",
            " 2   Marital Status          4024 non-null   object \n",
            " 3   Unnamed: 3              0 non-null      float64\n",
            " 4   T Stage                 4024 non-null   object \n",
            " 5   N Stage                 4024 non-null   object \n",
            " 6   6th Stage               4024 non-null   object \n",
            " 7   Grade                   4024 non-null   object \n",
            " 8   A Stage                 4024 non-null   object \n",
            " 9   Tumor Size              4024 non-null   int64  \n",
            " 10  Estrogen Status         4024 non-null   object \n",
            " 11  Progesterone Status     4024 non-null   object \n",
            " 12  Regional Node Examined  4024 non-null   int64  \n",
            " 13  Reginol Node Positive   4024 non-null   int64  \n",
            " 14  Survival Months         4024 non-null   int64  \n",
            " 15  Status                  4024 non-null   object \n",
            "dtypes: float64(1), int64(5), object(10)\n",
            "memory usage: 503.1+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "Age                          0\n",
            "Race                         0\n",
            "Marital Status               0\n",
            "Unnamed: 3                4024\n",
            "T Stage                      0\n",
            "N Stage                      0\n",
            "6th Stage                    0\n",
            "Grade                        0\n",
            "A Stage                      0\n",
            "Tumor Size                   0\n",
            "Estrogen Status              0\n",
            "Progesterone Status          0\n",
            "Regional Node Examined       0\n",
            "Reginol Node Positive        0\n",
            "Survival Months              0\n",
            "Status                       0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary:\n",
            "               Age  Unnamed: 3   Tumor Size  Regional Node Examined  \\\n",
            "count  4024.000000         0.0  4024.000000             4024.000000   \n",
            "mean     53.972167         NaN    30.473658               14.357107   \n",
            "std       8.963134         NaN    21.119696                8.099675   \n",
            "min      30.000000         NaN     1.000000                1.000000   \n",
            "25%      47.000000         NaN    16.000000                9.000000   \n",
            "50%      54.000000         NaN    25.000000               14.000000   \n",
            "75%      61.000000         NaN    38.000000               19.000000   \n",
            "max      69.000000         NaN   140.000000               61.000000   \n",
            "\n",
            "       Reginol Node Positive  Survival Months  \n",
            "count            4024.000000      4024.000000  \n",
            "mean                4.158052        71.297962  \n",
            "std                 5.109331        22.921430  \n",
            "min                 1.000000         1.000000  \n",
            "25%                 1.000000        56.000000  \n",
            "50%                 2.000000        73.000000  \n",
            "75%                 5.000000        90.000000  \n",
            "max                46.000000       107.000000  \n",
            "\n",
            "2. DATA PREPROCESSING\n",
            "--------------------------------------------------------------------------------\n",
            "Handling missing values...\n",
            "Dropping entirely missing columns: ['Unnamed: 3']\n",
            "Missing values after handling: 0\n",
            "\n",
            "Encoding categorical variables...\n",
            "  - Race : 3 unique values\n",
            "  - Marital Status: 5 unique values\n",
            "  - T Stage : 4 unique values\n",
            "  - N Stage: 3 unique values\n",
            "  - 6th Stage: 5 unique values\n",
            "  - Grade: 4 unique values\n",
            "  - A Stage: 2 unique values\n",
            "  - Estrogen Status: 2 unique values\n",
            "  - Progesterone Status: 2 unique values\n",
            "\n",
            "Target Variable (Status) encoded: {0: 'Alive', 1: 'Dead'}\n",
            "\n",
            "Target Distribution:\n",
            "Status\n",
            "0    3408\n",
            "1     616\n",
            "Name: count, dtype: int64\n",
            "Class Balance: Status\n",
            "0    0.846918\n",
            "1    0.153082\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "3. FEATURE ENGINEERING\n",
            "--------------------------------------------------------------------------------\n",
            "Created Age_Group feature\n",
            "Created Tumor_Category feature\n",
            "\n",
            "Total features after engineering: 17\n",
            "\n",
            "4. FEATURE SELECTION\n",
            "--------------------------------------------------------------------------------\n",
            "Features shape: (4024, 16)\n",
            "Target shape: (4024,)\n",
            "\n",
            "Features used: ['Age', 'Race ', 'Marital Status', 'T Stage ', 'N Stage', '6th Stage', 'Grade', 'A Stage', 'Tumor Size', 'Estrogen Status', 'Progesterone Status', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Age_Group', 'Tumor_Category']\n",
            "\n",
            "Top 10 Features Correlated with Target:\n",
            "Survival Months          0.476514\n",
            "6th Stage                0.257636\n",
            "Reginol Node Positive    0.256638\n",
            "N Stage                  0.255772\n",
            "Estrogen Status          0.184650\n",
            "Progesterone Status      0.177079\n",
            "T Stage                  0.154699\n",
            "Tumor Size               0.134205\n",
            "Tumor_Category           0.129718\n",
            "A Stage                  0.096584\n",
            "dtype: float64\n",
            "\n",
            "5. DATA SPLITTING AND SCALING\n",
            "--------------------------------------------------------------------------------\n",
            "Training set size: 3219 samples\n",
            "Test set size: 805 samples\n",
            "Training set class distribution:\n",
            "Status\n",
            "0    2726\n",
            "1     493\n",
            "Name: count, dtype: int64\n",
            "Test set class distribution:\n",
            "Status\n",
            "0    682\n",
            "1    123\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Features scaled using StandardScaler\n",
            "\n",
            "6. MODEL TRAINING\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  Accuracy: 0.9143\n",
            "  F1-Score: 0.6567\n",
            "  Cross-Val Mean: 0.8990 (+/- 0.0079)\n",
            "\n",
            "8. HYPERPARAMETER TUNING (Best Model)\n",
            "--------------------------------------------------------------------------------\n",
            "Tuning Gradient Boosting...\n",
            "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best cross-validation score: 0.9043\n",
            "Tuned model test accuracy: 0.9168\n",
            "\n",
            "9. FEATURE IMPORTANCE ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                   Feature  Importance\n",
            "13         Survival Months    0.826388\n",
            "0                      Age    0.047773\n",
            "12   Reginol Node Positive    0.033947\n",
            "5                6th Stage    0.025411\n",
            "9          Estrogen Status    0.017791\n",
            "10     Progesterone Status    0.015755\n",
            "4                  N Stage    0.015049\n",
            "8               Tumor Size    0.007246\n",
            "11  Regional Node Examined    0.003155\n",
            "1                    Race     0.002830\n",
            "\n",
            "10. ENSEMBLE MODEL (Not applicable - focusing on single model)\n",
            "--------------------------------------------------------------------------------\n",
            "Ensemble modeling section skipped as per user request to focus on Gradient Boosting.\n",
            "\n",
            "11. PROGNOSIS RECOMMENDATION SYSTEM\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example Patient Prognosis:\n",
            "\n",
            "Prediction: Dead\n",
            "Risk Level: Moderate Risk\n",
            "Survival Probability: 44.16%\n",
            "Death Probability: 55.84%\n",
            "\n",
            "Recommendations:\n",
            "  ‚ö†Ô∏è Higher risk of poor prognosis detected\n",
            "  üè• Recommend aggressive treatment approach\n",
            "  üìÖ Frequent follow-up monitoring (every 3-6 months)\n",
            "  üî¨ Consider additional diagnostic tests\n",
            "  üë• Multidisciplinary team consultation recommended\n",
            "\n",
            "12. MODEL COMPARISON SUMMARY (Gradient Boosting Only)\n",
            "--------------------------------------------------------------------------------\n",
            "Model                     Accuracy     F1-Score     CV Mean     \n",
            "--------------------------------------------------------------------------------\n",
            "Gradient Boosting         0.9168       0.6567       0.8990      \n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION SYSTEM COMPLETE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n==================================================================================\\nCOMPREHENSIVE EXPLANATION OF THE BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\\n(Focusing on Gradient Boosting Model)\\n==================================================================================\\n\\n1. PROJECT OVERVIEW:\\n   - Develops an ML-based system to predict breast cancer patient survival (Alive/Dead)\\n   - Uses SEER (Surveillance, Epidemiology, and End Results) dataset\\n   - Provides risk assessment and clinical recommendations, specifically using the Gradient Boosting model.\\n\\n2. DATA PREPROCESSING:\\n   - Handles missing values using median (numerical) and mode (categorical)\\n   - Encodes categorical variables (Race, Marital Status, T Stage, N Stage, etc.)\\n   - Target variable: Status (Alive=0, Dead=1).\\n   - Addresses class imbalance in dataset.\\n\\n3. FEATURE ENGINEERING:\\n   - Risk_Score: Combination of T Stage, N Stage, and Grade.\\n   - Age_Group: Categorical age bins for age-related patterns.\\n   - Tumor_Category: Categorizes tumor size into small/medium/large.\\n   - These engineered features capture domain knowledge about cancer prognosis.\\n\\n4. MODEL IMPLEMENTED:\\n   a) Gradient Boosting: A powerful ensemble model known for its high performance in classification tasks. It builds trees sequentially, with each new tree correcting errors made by previous ones.\\n\\n5. MODEL EVALUATION METRICS:\\n   - Accuracy: Overall correct predictions.\\n   - F1-Score: Harmonic mean of precision and recall.\\n   - Cross-Validation: 5-fold CV for robust performance estimation.\\n   - ROC-AUC: Area under ROC curve for classification quality.\\n   - Confusion Matrix: True/False Positives and Negatives.\\n\\n6. HYPERPARAMETER TUNING:\\n   - GridSearchCV was used to optimize the Gradient Boosting model's hyperparameters.\\n   - Parameters like `n_estimators`, `learning_rate`, `max_depth`, and `min_samples_split` were tuned to improve model generalization and performance.\\n\\n7. FEATURE IMPORTANCE:\\n   - Identifies most influential features for predictions from the Gradient Boosting model.\\n   - Helps understand which clinical factors matter most and guides clinical decision-making.\\n\\n8. RECOMMENDATION SYSTEM FUNCTIONALITY:\\n   - Takes patient data as input.\\n   - Predicts survival status (Alive/Dead) using the tuned Gradient Boosting model.\\n   - Calculates death probability.\\n   - Assigns risk level (Low/Moderate/High).\\n   - Generates personalized clinical recommendations based on the prediction and risk level:\\n     * Treatment intensity (standard vs aggressive).\\n     * Follow-up frequency (3-6 months vs 6-12 months).\\n     * Additional diagnostic tests.\\n     * Lifestyle modifications.\\n     * Specialist consultations.\\n\\n9. CLINICAL RECOMMENDATIONS LOGIC:\\n   - High Risk (Death Prob > 60%):\\n     * Aggressive treatment approach.\\n     * Frequent monitoring every 3-6 months.\\n     * Multidisciplinary team consultation.\\n   - Low Risk (Death Prob < 30%):\\n     * Standard treatment protocol.\\n     * Regular monitoring every 6-12 months.\\n     * Lifestyle modifications.\\n   - Feature-specific recommendations:\\n     * Large tumors ‚Üí Neoadjuvant therapy.\\n     * High-grade tumors ‚Üí Adjuvant chemotherapy.\\n\\n10. KEY FEATURES FROM DATASET:\\n    - Age: Patient age at diagnosis.\\n    - Tumor Size: Size in millimeters.\\n    - T Stage: Tumor stage (T1, T2, T3, T4).\\n    - N Stage: Lymph node involvement (N0, N1, N2, N3).\\n    - Grade: Cell differentiation (Well/Moderate/Poorly differentiated).\\n    - Hormone Status: Estrogen/Progesterone receptor status.\\n    - Regional Node Positive: Number of positive lymph nodes.\\n    - 6th Stage: Overall cancer stage (I, II, III, IV).\\n\\n11. MODEL PERFORMANCE CONSIDERATIONS:\\n    - Training/Test Split: 80/20 with stratification.\\n    - Feature Scaling: StandardScaler for normalized features.\\n    - Cross-Validation: 5-fold to prevent overfitting.\\n    - Handles imbalanced classes appropriately.\\n\\n12. PRACTICAL USAGE:\\n    - Input: Patient clinical data (demographics, tumor characteristics, treatment).\\n    - Output: Survival prediction, risk level, actionable recommendations.\\n    - Can be integrated into hospital information systems.\\n    - Supports clinical decision-making, not replacement.\\n\\n13. LIMITATIONS & CONSIDERATIONS:\\n    - Model predictions are probabilistic, not deterministic.\\n    - Should be used alongside clinical expertise.\\n    - Regular retraining needed with new data.\\n    - Performance depends on data quality and representativeness.\\n\\n14. VISUALIZATIONS CREATED (for Gradient Boosting model):\\n    - Model accuracy bar chart.\\n    - Confusion matrix heatmap.\\n    - Feature importance plot.\\n    - ROC curve.\\n\\n15. FUTURE ENHANCEMENTS:\\n    - Deep learning models (Neural Networks).\\n    - Survival analysis (time-to-event modeling).\\n    - Integration with treatment response data.\\n    - Real-time prediction API.\\n    - Explainable AI techniques (SHAP, LIME).\\n\\n16. MEDICAL SIGNIFICANCE:\\n    - Early identification of high-risk patients.\\n    - Personalized treatment planning.\\n    - Resource optimization in healthcare.\\n    - Improved patient outcomes through data-driven decisions.\\n\\n==================================================================================\\nThis system demonstrates the power of machine learning in healthcare, providing\\nevidence-based recommendations to support oncologists in breast cancer prognosis\\nand treatment planning, specifically utilizing the robust Gradient Boosting model.\\n==================================================================================\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                            roc_auc_score, roc_curve, precision_recall_curve, f1_score)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==================== 1. DATA LOADING AND EXPLORATION ====================\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('RS-A4_SEER Breast Cancer Dataset .csv')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n1. DATASET OVERVIEW\")\n",
        "print(\"-\"*80)\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# ==================== 2. DATA PREPROCESSING ====================\n",
        "\n",
        "print(\"\\n2. DATA PREPROCESSING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create a copy for processing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Handle missing values\n",
        "print(\"Handling missing values...\")\n",
        "# Drop columns that are entirely missing (like 'Unnamed: 3') as they provide no information\n",
        "cols_to_drop_entirely = [col for col in df_processed.columns if df_processed[col].isnull().all()]\n",
        "if cols_to_drop_entirely:\n",
        "    print(f\"Dropping entirely missing columns: {cols_to_drop_entirely}\")\n",
        "    df_processed.drop(columns=cols_to_drop_entirely, inplace=True)\n",
        "\n",
        "# Fill remaining missing values\n",
        "for col in df_processed.columns:\n",
        "    if df_processed[col].isnull().sum() > 0:\n",
        "        if df_processed[col].dtype in ['int64', 'float64']:\n",
        "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "        else:\n",
        "            df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
        "\n",
        "print(\"Missing values after handling:\", df_processed.isnull().sum().sum())\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"\\nEncoding categorical variables...\")\n",
        "label_encoders = {}\n",
        "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col != 'Status':  # Keep Status for last\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"  - {col}: {len(le.classes_)} unique values\")\n",
        "\n",
        "# Encode target variable (Status: Alive=0, Dead=1)\n",
        "if 'Status' in df_processed.columns:\n",
        "    le_status = LabelEncoder()\n",
        "    df_processed['Status'] = le_status.fit_transform(df_processed['Status'])\n",
        "    label_encoders['Status'] = le_status\n",
        "    print(f\"\\nTarget Variable (Status) encoded: {dict(enumerate(le_status.classes_))}\")\n",
        "\n",
        "# Check target distribution\n",
        "print(\"\\nTarget Distribution:\")\n",
        "print(df_processed['Status'].value_counts())\n",
        "print(f\"Class Balance: {df_processed['Status'].value_counts(normalize=True)}\")\n",
        "\n",
        "# ==================== 3. FEATURE ENGINEERING ====================\n",
        "\n",
        "print(\"\\n3. FEATURE ENGINEERING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create risk score based on clinical features\n",
        "if all(col in df_processed.columns for col in ['T Stage', 'N Stage', 'Grade']):\n",
        "    df_processed['Risk_Score'] = (df_processed['T Stage'] +\n",
        "                                  df_processed['N Stage'] +\n",
        "                                  df_processed['Grade']) / 3\n",
        "    print(\"Created Risk_Score feature\")\n",
        "\n",
        "# Create age groups\n",
        "if 'Age' in df_processed.columns:\n",
        "    df_processed['Age_Group'] = pd.cut(df_processed['Age'],\n",
        "                                       bins=[0, 40, 50, 60, 70, 100],\n",
        "                                       labels=[0, 1, 2, 3, 4])\n",
        "    df_processed['Age_Group'] = df_processed['Age_Group'].astype(int)\n",
        "    print(\"Created Age_Group feature\")\n",
        "\n",
        "# Tumor size category\n",
        "if 'Tumor Size' in df_processed.columns:\n",
        "    # Adjust bins to ensure all 'Tumor Size' values are covered\n",
        "    # The max tumor size in the dataset is 140. We extend the last bin boundary.\n",
        "    max_current_bin_edge = 100\n",
        "    max_data_tumor_size = df_processed['Tumor Size'].max()\n",
        "    adjusted_upper_bin_edge = max(max_current_bin_edge, max_data_tumor_size) # Use the larger of 100 or actual max\n",
        "\n",
        "    df_processed['Tumor_Category'] = pd.cut(df_processed['Tumor Size'],\n",
        "                                            bins=[0, 20, 50, adjusted_upper_bin_edge],\n",
        "                                            labels=[0, 1, 2],\n",
        "                                            right=True, # Intervals are (a, b]\n",
        "                                            include_lowest=True) # Ensure values from the lowest bin boundary (like 0) are included\n",
        "\n",
        "    df_processed['Tumor_Category'] = df_processed['Tumor_Category'].astype(int)\n",
        "    print(\"Created Tumor_Category feature\")\n",
        "\n",
        "print(f\"\\nTotal features after engineering: {df_processed.shape[1]}\")\n",
        "\n",
        "# ==================== 4. FEATURE SELECTION ====================\n",
        "\n",
        "print(\"\\n4. FEATURE SELECTION\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Separate features and target\n",
        "X = df_processed.drop('Status', axis=1)\n",
        "y = df_processed['Status']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeatures used: {list(X.columns)}\")\n",
        "\n",
        "# Feature correlation analysis\n",
        "correlation_matrix = X.corrwith(y).abs().sort_values(ascending=False)\n",
        "print(\"\\nTop 10 Features Correlated with Target:\")\n",
        "print(correlation_matrix.head(10))\n",
        "\n",
        "# ==================== 5. DATA SPLITTING AND SCALING ====================\n",
        "\n",
        "print(\"\\n5. DATA SPLITTING AND SCALING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n",
        "print(f\"Test set class distribution:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nFeatures scaled using StandardScaler\")\n",
        "\n",
        "# ==================== 6. MODEL TRAINING ====================\n",
        "\n",
        "print(\"\\n6. MODEL TRAINING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Initialize only the Gradient Boosting model\n",
        "models = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models (will only run for Gradient Boosting)\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'predictions': y_pred,\n",
        "        'probabilities': y_pred_proba\n",
        "    }\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  Cross-Val Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "# ==================== 7. MODEL EVALUATION ====================\n",
        "\n",
        "#print(\"\\n7. MODEL EVALUATION\")\n",
        "#print(\"-\"*80)\n",
        "\n",
        "# Best model is now explicitly Gradient Boosting\n",
        "best_model_name = 'Gradient Boosting'\n",
        "#best_model = trained_models[best_model_name]\n",
        "\n",
        "#print(f\"\\nBest Model: {best_model_name}\")\n",
        "#print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
        "#print(f\"F1-Score: {results[best_model_name]['f1_score']:.4f}\")\n",
        "\n",
        "# Detailed classification report for best model\n",
        "#print(f\"\\nClassification Report for {best_model_name}:\")\n",
        "#print(classification_report(y_test, results[best_model_name]['predictions'],\n",
        "#                          target_names=['Alive', 'Dead']))\n",
        "\n",
        "# Confusion Matrix\n",
        "#print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
        "#cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
        "#print(cm)\n",
        "\n",
        "# ==================== 8. HYPERPARAMETER TUNING ====================\n",
        "\n",
        "print(\"\\n8. HYPERPARAMETER TUNING (Best Model)\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Parameter grid for Gradient Boosting\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "base_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "print(f\"Tuning {best_model_name}...\")\n",
        "grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Update best model to the tuned one\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Re-evaluate tuned model\n",
        "y_pred_tuned = best_model.predict(X_test_scaled)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "print(f\"Tuned model test accuracy: {accuracy_tuned:.4f}\")\n",
        "\n",
        "# Update results for 'Gradient Boosting' with tuned model's predictions/probabilities\n",
        "results[best_model_name]['predictions'] = y_pred_tuned\n",
        "if hasattr(best_model, 'predict_proba'):\n",
        "    results[best_model_name]['probabilities'] = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "results[best_model_name]['accuracy'] = accuracy_tuned\n",
        "\n",
        "# ==================== 9. FEATURE IMPORTANCE ====================\n",
        "\n",
        "print(\"\\n9. FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "# ==================== 10. ENSEMBLE MODEL ====================\n",
        "\n",
        "print(\"\\n10. ENSEMBLE MODEL (Not applicable - focusing on single model)\")\n",
        "print(\"-\"*80)\n",
        "print(\"Ensemble modeling section skipped as per user request to focus on Gradient Boosting.\")\n",
        "# Removed ensemble creation and evaluation for simplicity\n",
        "ensemble_model = best_model # For compatibility with recommendation function\n",
        "\n",
        "# ==================== 11. RECOMMENDATION FUNCTION ====================\n",
        "\n",
        "print(\"\\n11. PROGNOSIS RECOMMENDATION SYSTEM\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "def predict_prognosis(patient_data, model, scaler, feature_names, encoders):\n",
        "    \"\"\"\n",
        "    Predict breast cancer prognosis and provide recommendations\n",
        "\n",
        "    Parameters:\n",
        "    - patient_data: dict with patient information\n",
        "    - model: trained ML model\n",
        "    - scaler: fitted StandardScaler\n",
        "    - feature_names: list of feature names\n",
        "    - encoders: dict of label encoders\n",
        "\n",
        "    Returns:\n",
        "    - prediction, probability, risk_level, recommendations\n",
        "    \"\"\"\n",
        "    # Prepare input data\n",
        "    patient_df = pd.DataFrame([patient_data])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    for col, encoder in encoders.items():\n",
        "        if col in patient_df.columns and col != 'Status':\n",
        "            try:\n",
        "                patient_df[col] = encoder.transform(patient_df[col].astype(str))\n",
        "            except:\n",
        "                patient_df[col] = 0  # Default value if encoding fails\n",
        "\n",
        "    # Ensure all features are present\n",
        "    for col in feature_names:\n",
        "        if col not in patient_df.columns:\n",
        "            patient_df[col] = 0\n",
        "\n",
        "    # Select and order features\n",
        "    patient_df = patient_df[feature_names]\n",
        "\n",
        "    # Scale features\n",
        "    patient_scaled = scaler.transform(patient_df)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(patient_scaled)[0]\n",
        "    probability = model.predict_proba(patient_scaled)[0] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Determine risk level\n",
        "    if probability is not None:\n",
        "        death_prob = probability[1]\n",
        "        if death_prob < 0.3:\n",
        "            risk_level = \"Low Risk\"\n",
        "        elif death_prob < 0.6:\n",
        "            risk_level = \"Moderate Risk\"\n",
        "        else:\n",
        "            risk_level = \"High Risk\"\n",
        "    else:\n",
        "        risk_level = \"Unable to determine\"\n",
        "\n",
        "    # Generate recommendations\n",
        "    recommendations = []\n",
        "\n",
        "    if prediction == 1 or (probability is not None and probability[1] > 0.5):\n",
        "        recommendations.append(\"‚ö†Ô∏è Higher risk of poor prognosis detected\")\n",
        "        recommendations.append(\"üè• Recommend aggressive treatment approach\")\n",
        "        recommendations.append(\"üìÖ Frequent follow-up monitoring (every 3-6 months)\")\n",
        "        recommendations.append(\"üî¨ Consider additional diagnostic tests\")\n",
        "        recommendations.append(\"üë• Multidisciplinary team consultation recommended\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Lower risk prognosis indicated\")\n",
        "        recommendations.append(\"üíä Standard treatment protocol recommended\")\n",
        "        recommendations(\"üìÖ Regular follow-up monitoring (every 6-12 months)\")\n",
        "        recommendations.append(\"üèÉ Encourage healthy lifestyle modifications\")\n",
        "\n",
        "    # Add specific recommendations based on features\n",
        "    if 'Tumor Size' in patient_data and patient_data['Tumor Size'] > 50:\n",
        "        recommendations.append(\"‚öïÔ∏è Large tumor size - consider neoadjuvant therapy\")\n",
        "\n",
        "    if 'Grade' in patient_data and 'Poorly' in str(patient_data['Grade']):\n",
        "        recommendations.append(\"üî¨ High-grade tumor - consider adjuvant chemotherapy\")\n",
        "\n",
        "    return {\n",
        "        'prediction': 'Dead' if prediction == 1 else 'Alive',\n",
        "        'probability': probability,\n",
        "        'risk_level': risk_level,\n",
        "        'recommendations': recommendations\n",
        "    }\n",
        "\n",
        "# Example prediction (using the tuned best_model, which is Gradient Boosting)\n",
        "print(\"\\nExample Patient Prognosis:\")\n",
        "example_patient = {\n",
        "    'Age': 55,\n",
        "    'Race': 'White',\n",
        "    'Marital Status': 'Married (including common law)',\n",
        "    'T Stage': 'T2',\n",
        "    'N Stage': 'N1',\n",
        "    '6th Stage': 'IIB',\n",
        "    'Grade': 'Moderate',\n",
        "    'A Stage': 'Regional',\n",
        "    'Tumor Size': 35,\n",
        "    'Estrogen Status': 'Positive',\n",
        "    'Progesterone Status': 'Positive',\n",
        "    'Regional Node Examined': 15,\n",
        "    'Reginol Node Positive': 3,\n",
        "    'Survival Months': 24\n",
        "}\n",
        "\n",
        "result = predict_prognosis(example_patient, best_model, scaler, # Use best_model here\n",
        "                          X.columns.tolist(), label_encoders)\n",
        "\n",
        "print(f\"\\nPrediction: {result['prediction']}\")\n",
        "print(f\"Risk Level: {result['risk_level']}\")\n",
        "if result['probability'] is not None:\n",
        "    print(f\"Survival Probability: {result['probability'][0]:.2%}\")\n",
        "    print(f\"Death Probability: {result['probability'][1]:.2%}\")\n",
        "print(\"\\nRecommendations:\")\n",
        "for rec in result['recommendations']:\n",
        "    print(f\"  {rec}\")\n",
        "\n",
        "# ==================== 12. MODEL COMPARISON SUMMARY ====================\n",
        "\n",
        "print(\"\\n12. MODEL COMPARISON SUMMARY (Gradient Boosting Only)\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Model':<25} {'Accuracy':<12} {'F1-Score':<12} {'CV Mean':<12}\")\n",
        "print(\"-\"*80)\n",
        "# Only show Gradient Boosting results\n",
        "metrics = results[best_model_name]\n",
        "print(f\"{best_model_name:<25} {metrics['accuracy'] if 'accuracy' in metrics else 'N/A':<12.4f} {metrics['f1_score'] if 'f1_score' in metrics else 'N/A':<12.4f} {metrics['cv_mean'] if 'cv_mean' in metrics else 'N/A':<12.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATION SYSTEM COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==================== VISUALIZATION CODE (Optional) ====================\n",
        "\n",
        "# Create visualizations\n",
        "# fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Model Comparison (now only for Gradient Boosting)\n",
        "# model_names_single = [best_model_name]\n",
        "# accuracies_single = [results[best_model_name]['accuracy']]\n",
        "# axes[0, 0].bar(model_names_single, accuracies_single, color='skyblue')\n",
        "# axes[0, 0].set_ylabel('Accuracy')\n",
        "# axes[0, 0].set_title(f'Accuracy - {best_model_name}')\n",
        "# axes[0, 0].set_ylim([0.6, 1.0])\n",
        "\n",
        "# 2. Confusion Matrix for Best Model (Gradient Boosting)\n",
        "# cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],\n",
        "#             xticklabels=['Alive', 'Dead'], yticklabels=['Alive', 'Dead'])\n",
        "# axes[0, 1].set_title(f'Confusion Matrix - {best_model_name}')\n",
        "# axes[0, 1].set_ylabel('True Label')\n",
        "# axes[0, 1].set_xlabel('Predicted Label')\n",
        "\n",
        "# 3. Feature Importance (if available for Gradient Boosting)\n",
        "# if hasattr(best_model, 'feature_importances_'):\n",
        "#     feature_importance = pd.DataFrame({\n",
        "#         'Feature': X.columns,\n",
        "#         'Importance': best_model.feature_importances_\n",
        "#     }).sort_values('Importance', ascending=False)\n",
        "#     top_features = feature_importance.head(10)\n",
        "#     axes[1, 0].barh(range(len(top_features)), top_features['Importance'])\n",
        "#     axes[1, 0].set_yticks(range(len(top_features)))\n",
        "#     axes[1, 0].set_yticklabels(top_features['Feature'])\n",
        "#     axes[1, 0].set_xlabel('Importance')\n",
        "#     axes[1, 0].set_title('Top 10 Feature Importance (Gradient Boosting)')\n",
        "#     axes[1, 0].invert_yaxis()\n",
        "\n",
        "# 4. ROC Curve (for Gradient Boosting)\n",
        "# if results[best_model_name]['probabilities'] is not None:\n",
        "#     fpr, tpr, _ = roc_curve(y_test, results[best_model_name]['probabilities'])\n",
        "#     auc_score = roc_auc_score(y_test, results[best_model_name]['probabilities'])\n",
        "#     axes[1, 1].plot(fpr, tpr, label=f'{best_model_name} (AUC = {auc_score:.3f})')\n",
        "#     axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "#     axes[1, 1].set_xlabel('False Positive Rate')\n",
        "#     axes[1, 1].set_ylabel('True Positive Rate')\n",
        "#     axes[1, 1].set_title('ROC Curve (Gradient Boosting)')\n",
        "#     axes[1, 1].legend()\n",
        "#     axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('breast_cancer_ml_analysis.png', dpi=300, bbox_inches='tight')\n",
        "# print(\"\\nVisualizations saved to 'breast_cancer_ml_analysis.png'\")\n",
        "\n",
        "\"\"\"\n",
        "==================================================================================\n",
        "COMPREHENSIVE EXPLANATION OF THE BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\n",
        "(Focusing on Gradient Boosting Model)\n",
        "==================================================================================\n",
        "\n",
        "1. PROJECT OVERVIEW:\n",
        "   - Develops an ML-based system to predict breast cancer patient survival (Alive/Dead)\n",
        "   - Uses SEER (Surveillance, Epidemiology, and End Results) dataset\n",
        "   - Provides risk assessment and clinical recommendations, specifically using the Gradient Boosting model.\n",
        "\n",
        "2. DATA PREPROCESSING:\n",
        "   - Handles missing values using median (numerical) and mode (categorical)\n",
        "   - Encodes categorical variables (Race, Marital Status, T Stage, N Stage, etc.)\n",
        "   - Target variable: Status (Alive=0, Dead=1).\n",
        "   - Addresses class imbalance in dataset.\n",
        "\n",
        "3. FEATURE ENGINEERING:\n",
        "   - Risk_Score: Combination of T Stage, N Stage, and Grade.\n",
        "   - Age_Group: Categorical age bins for age-related patterns.\n",
        "   - Tumor_Category: Categorizes tumor size into small/medium/large.\n",
        "   - These engineered features capture domain knowledge about cancer prognosis.\n",
        "\n",
        "4. MODEL IMPLEMENTED:\n",
        "   a) Gradient Boosting: A powerful ensemble model known for its high performance in classification tasks. It builds trees sequentially, with each new tree correcting errors made by previous ones.\n",
        "\n",
        "5. MODEL EVALUATION METRICS:\n",
        "   - Accuracy: Overall correct predictions.\n",
        "   - F1-Score: Harmonic mean of precision and recall.\n",
        "   - Cross-Validation: 5-fold CV for robust performance estimation.\n",
        "   - ROC-AUC: Area under ROC curve for classification quality.\n",
        "   - Confusion Matrix: True/False Positives and Negatives.\n",
        "\n",
        "6. HYPERPARAMETER TUNING:\n",
        "   - GridSearchCV was used to optimize the Gradient Boosting model's hyperparameters.\n",
        "   - Parameters like `n_estimators`, `learning_rate`, `max_depth`, and `min_samples_split` were tuned to improve model generalization and performance.\n",
        "\n",
        "7. FEATURE IMPORTANCE:\n",
        "   - Identifies most influential features for predictions from the Gradient Boosting model.\n",
        "   - Helps understand which clinical factors matter most and guides clinical decision-making.\n",
        "\n",
        "8. RECOMMENDATION SYSTEM FUNCTIONALITY:\n",
        "   - Takes patient data as input.\n",
        "   - Predicts survival status (Alive/Dead) using the tuned Gradient Boosting model.\n",
        "   - Calculates death probability.\n",
        "   - Assigns risk level (Low/Moderate/High).\n",
        "   - Generates personalized clinical recommendations based on the prediction and risk level:\n",
        "     * Treatment intensity (standard vs aggressive).\n",
        "     * Follow-up frequency (3-6 months vs 6-12 months).\n",
        "     * Additional diagnostic tests.\n",
        "     * Lifestyle modifications.\n",
        "     * Specialist consultations.\n",
        "\n",
        "9. CLINICAL RECOMMENDATIONS LOGIC:\n",
        "   - High Risk (Death Prob > 60%):\n",
        "     * Aggressive treatment approach.\n",
        "     * Frequent monitoring every 3-6 months.\n",
        "     * Multidisciplinary team consultation.\n",
        "   - Low Risk (Death Prob < 30%):\n",
        "     * Standard treatment protocol.\n",
        "     * Regular monitoring every 6-12 months.\n",
        "     * Lifestyle modifications.\n",
        "   - Feature-specific recommendations:\n",
        "     * Large tumors ‚Üí Neoadjuvant therapy.\n",
        "     * High-grade tumors ‚Üí Adjuvant chemotherapy.\n",
        "\n",
        "10. KEY FEATURES FROM DATASET:\n",
        "    - Age: Patient age at diagnosis.\n",
        "    - Tumor Size: Size in millimeters.\n",
        "    - T Stage: Tumor stage (T1, T2, T3, T4).\n",
        "    - N Stage: Lymph node involvement (N0, N1, N2, N3).\n",
        "    - Grade: Cell differentiation (Well/Moderate/Poorly differentiated).\n",
        "    - Hormone Status: Estrogen/Progesterone receptor status.\n",
        "    - Regional Node Positive: Number of positive lymph nodes.\n",
        "    - 6th Stage: Overall cancer stage (I, II, III, IV).\n",
        "\n",
        "11. MODEL PERFORMANCE CONSIDERATIONS:\n",
        "    - Training/Test Split: 80/20 with stratification.\n",
        "    - Feature Scaling: StandardScaler for normalized features.\n",
        "    - Cross-Validation: 5-fold to prevent overfitting.\n",
        "    - Handles imbalanced classes appropriately.\n",
        "\n",
        "12. PRACTICAL USAGE:\n",
        "    - Input: Patient clinical data (demographics, tumor characteristics, treatment).\n",
        "    - Output: Survival prediction, risk level, actionable recommendations.\n",
        "    - Can be integrated into hospital information systems.\n",
        "    - Supports clinical decision-making, not replacement.\n",
        "\n",
        "13. LIMITATIONS & CONSIDERATIONS:\n",
        "    - Model predictions are probabilistic, not deterministic.\n",
        "    - Should be used alongside clinical expertise.\n",
        "    - Regular retraining needed with new data.\n",
        "    - Performance depends on data quality and representativeness.\n",
        "\n",
        "14. VISUALIZATIONS CREATED (for Gradient Boosting model):\n",
        "    - Model accuracy bar chart.\n",
        "    - Confusion matrix heatmap.\n",
        "    - Feature importance plot.\n",
        "    - ROC curve.\n",
        "\n",
        "15. FUTURE ENHANCEMENTS:\n",
        "    - Deep learning models (Neural Networks).\n",
        "    - Survival analysis (time-to-event modeling).\n",
        "    - Integration with treatment response data.\n",
        "    - Real-time prediction API.\n",
        "    - Explainable AI techniques (SHAP, LIME).\n",
        "\n",
        "16. MEDICAL SIGNIFICANCE:\n",
        "    - Early identification of high-risk patients.\n",
        "    - Personalized treatment planning.\n",
        "    - Resource optimization in healthcare.\n",
        "    - Improved patient outcomes through data-driven decisions.\n",
        "\n",
        "==================================================================================\n",
        "This system demonstrates the power of machine learning in healthcare, providing\n",
        "evidence-based recommendations to support oncologists in breast cancer prognosis\n",
        "and treatment planning, specifically utilizing the robust Gradient Boosting model.\n",
        "==================================================================================\n",
        "\"\"\""
      ]
    }
  ]
}